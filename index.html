<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>identibench</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./https://raw.githubusercontent.com/daniel-om-weber/identibench/main/assets/logo.svg" rel="icon" type="image/svg+xml">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-0c9eb0277ab99f059f9e902403bd7a3d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="identibench">
<meta property="og:description" content="Downloads and prepares various system identification benchmark datasets">
<meta property="og:site_name" content="identibench">
<meta name="twitter:title" content="identibench">
<meta name="twitter:description" content="Downloads and prepares various system identification benchmark datasets">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="https://raw.githubusercontent.com/daniel-om-weber/identibench/main/assets/logo.svg" alt="identibench logo" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">identibench</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./index.html">IdentiBench</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">IdentiBench</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./benchmark.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Benchmark</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Metrics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./utils.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Utilities</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">datasets</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets/broad.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Berlin Robust Orientation Estimation Assessment Dataset (BROAD)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets/industrial_robot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Industrial Robot Dataset</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets/quad_pelican.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quadrotor Pelican Dataset</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets/quadrotor_pi.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quadrotor PI Dataset</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets/ship.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ship Dataset</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets/workshop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nonlinear Benchmark Workshop Datasets</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#identibench" id="toc-identibench" class="nav-link active" data-scroll-target="#identibench">IdentiBench</a></li>
  <li><a href="#key-features" id="toc-key-features" class="nav-link" data-scroll-target="#key-features">Key Features</a></li>
  <li><a href="#installation" id="toc-installation" class="nav-link" data-scroll-target="#installation">Installation</a></li>
  <li><a href="#simulation-benchmarks" id="toc-simulation-benchmarks" class="nav-link" data-scroll-target="#simulation-benchmarks">Simulation Benchmarks</a></li>
  <li><a href="#prediction-benchmarks" id="toc-prediction-benchmarks" class="nav-link" data-scroll-target="#prediction-benchmarks">Prediction Benchmarks</a></li>
  <li><a href="#workflow-details" id="toc-workflow-details" class="nav-link" data-scroll-target="#workflow-details">Workflow Details</a>
  <ul class="collapse">
  <li><a href="#benchmark-types" id="toc-benchmark-types" class="nav-link" data-scroll-target="#benchmark-types">Benchmark Types</a></li>
  <li><a href="#model-interface-build_model" id="toc-model-interface-build_model" class="nav-link" data-scroll-target="#model-interface-build_model">Model Interface (<code>build_model</code>)</a></li>
  <li><a href="#running-multiple-benchmarks" id="toc-running-multiple-benchmarks" class="nav-link" data-scroll-target="#running-multiple-benchmarks">Running Multiple Benchmarks</a></li>
  <li><a href="#data-handling-format" id="toc-data-handling-format" class="nav-link" data-scroll-target="#data-handling-format">Data Handling &amp; Format</a></li>
  <li><a href="#understanding-benchmark-results" id="toc-understanding-benchmark-results" class="nav-link" data-scroll-target="#understanding-benchmark-results">Understanding Benchmark Results</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/daniel-om-weber/identibench/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<p><img src="https://raw.githubusercontent.com/daniel-om-weber/identibench/main/assets/logo.svg" width="200" align="left" alt="identibench logo"></p>
<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="identibench" class="level2">
<h2 class="anchored" data-anchor-id="identibench">IdentiBench</h2>
<p><a href="https://badge.fury.io/py/identibench"><img src="https://badge.fury.io/py/identibench.svg" class="img-fluid" alt="PyPI version"></a> <a href="https://opensource.org/licenses/Apache-2.0"><img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" class="img-fluid" alt="License: Apache 2.0"></a> <a href="https://daniel-om-weber.github.io/identibench/"><img src="https://img.shields.io/badge/docs-up_to_date-brightgreen.svg" class="img-fluid" alt="Docs Status"></a> <a href="https://pypi.org/project/identibench/"><img src="https://img.shields.io/pypi/pyversions/identibench.png" class="img-fluid" alt="Python Versions"></a></p>
<p>IdentiBench is a Python library designed to streamline and standardize the benchmarking of system identification models. Evaluating and comparing dynamic models often requires repetitive setup for data handling, evaluation protocols, and metrics implementation, making fair comparisons and reproducing results challenging. IdentiBench tackles this by offering a collection of pre-defined benchmark specifications for simulation and prediction tasks, built upon common datasets. It automates data downloading and processing into a consistent format and provides standard evaluation metrics via a simple interface (run_benchmark). This allows you to focus your efforts on developing innovative models, while relying on IdentiBench for robust and reproducible evaluation.</p>
</section>
<section id="key-features" class="level2">
<h2 class="anchored" data-anchor-id="key-features">Key Features</h2>
<ul>
<li><strong>Access Many Benchmarks from different systems:</strong> Instantly utilize pre-configured benchmarks covering diverse domains like electronics (Silverbox), mechanics (Industrial Robot), process control (Cascaded Tanks), aerospace (Quadrotors), and more, available for both simulation and prediction tasks.</li>
<li><strong>Automate Data Management:</strong> Forget manual downloading and processing; the library handles fetching data from various sources (web, Drive, Dataverse), extracting archives (ZIP, RAR, MAT, BAG), converting to a standard HDF5 format, and caching locally.</li>
<li><strong>Integrate Any Model to evaluate on all benchmarks:</strong> Plug in your custom models, regardless of the Python framework used (NumPy, SciPy, PyTorch, TensorFlow, JAX, etc.), using a straightforward function interface (<code>build_model</code>) that receives all necessary context.</li>
<li><strong>Capture Comprehensive Results:</strong> Obtain detailed evaluation reports including standard metrics (RMSE, NRMSE, FIT%, etc.), task-specific scores, execution timings, configuration parameters (hyperparameters, seed), and raw model predictions for thorough analysis.</li>
<li><strong>Easily Define New Benchmarks:</strong> Go beyond the included datasets by creating your own benchmark specifications (<a href="https://daniel-om-weber.github.io/identibench/benchmark.html#benchmarkspecsimulation"><code>BenchmarkSpecSimulation</code></a>, <a href="https://daniel-om-weber.github.io/identibench/benchmark.html#benchmarkspecprediction"><code>BenchmarkSpecPrediction</code></a>) for private data or unique tasks, leveraging the library’s structure and transparent data format.</li>
</ul>
</section>
<section id="installation" class="level2">
<h2 class="anchored" data-anchor-id="installation">Installation</h2>
<p>You can install <code>identibench</code> using pip:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install identibench</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To install the latest development version directly from GitHub, use:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install git+https://github.com/daniel-om-weber/identibench.git</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Basic usage</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> identibench <span class="im">as</span> idb</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Download a single dataset</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: Always use a Path object, not a string</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>save_path <span class="op">=</span> Path(<span class="st">'./tmp/wh'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>idb.datasets.workshop.dl_wiener_hammerstein(save_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-6" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sysidentpy.model_structure_selection <span class="im">import</span> FROLS</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sysidentpy.parameter_estimation <span class="im">import</span> LeastSquares</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_frols_model(context):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    u_train, y_train, _ <span class="op">=</span> <span class="bu">next</span>(context.get_train_sequences())</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    ylag <span class="op">=</span> context.hyperparameters.get(<span class="st">'ylag'</span>, <span class="dv">5</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    xlag <span class="op">=</span> context.hyperparameters.get(<span class="st">'xlag'</span>, <span class="dv">5</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    n_terms <span class="op">=</span> context.hyperparameters.get(<span class="st">'n_terms'</span>, <span class="dv">10</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    estimator <span class="op">=</span> context.hyperparameters.get(<span class="st">'estimator'</span>, LeastSquares())</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    _model <span class="op">=</span> FROLS(xlag<span class="op">=</span>xlag, ylag<span class="op">=</span>ylag, n_terms<span class="op">=</span>n_terms,estimator<span class="op">=</span>estimator)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    _model.fit(X<span class="op">=</span>u_train, y<span class="op">=</span>y_train)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> model(u_test, y_init):</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="kw">nonlocal</span> _model</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        yhat_full <span class="op">=</span> _model.predict(X<span class="op">=</span>u_test, y<span class="op">=</span>y_init[:_model.max_lag])</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> yhat_full[_model.max_lag:]</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> y_pred</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-7" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>hyperparams <span class="op">=</span> {</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ylag'</span>: <span class="dv">2</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'xlag'</span>: <span class="dv">2</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_terms'</span>: <span class="dv">10</span>, <span class="co"># Number of terms for FROLS</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'estimator'</span>: LeastSquares()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> idb.run_benchmark(</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    spec<span class="op">=</span>idb.BenchmarkWH_Simulation,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    build_model<span class="op">=</span>build_frols_model,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    hyperparameters<span class="op">=</span>hyperparams</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="simulation-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="simulation-benchmarks">Simulation Benchmarks</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Key</th>
<th>Benchmark Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>WH_Sim</code></td>
<td>BenchmarkWH_Simulation</td>
</tr>
<tr class="even">
<td><code>Silverbox_Sim</code></td>
<td>BenchmarkSilverbox_Simulation</td>
</tr>
<tr class="odd">
<td><code>Tanks_Sim</code></td>
<td>BenchmarkCascadedTanks_Simulation</td>
</tr>
<tr class="even">
<td><code>CED_Sim</code></td>
<td>BenchmarkCED_Simulation</td>
</tr>
<tr class="odd">
<td><code>EMPS_Sim</code></td>
<td>BenchmarkEMPS_Simulation</td>
</tr>
<tr class="even">
<td><code>NoisyWH_Sim</code></td>
<td>BenchmarkNoisyWH_Simulation</td>
</tr>
<tr class="odd">
<td><code>RobotForward_Sim</code></td>
<td>BenchmarkRobotForward_Simulation</td>
</tr>
<tr class="even">
<td><code>RobotInverse_Sim</code></td>
<td>BenchmarkRobotInverse_Simulation</td>
</tr>
<tr class="odd">
<td><code>Ship_Sim</code></td>
<td>BenchmarkShip_Simulation</td>
</tr>
<tr class="even">
<td><code>QuadPelican_Sim</code></td>
<td>BenchmarkQuadPelican_Simulation</td>
</tr>
<tr class="odd">
<td><code>QuadPi_Sim</code></td>
<td>BenchmarkQuadPi_Simulation</td>
</tr>
</tbody>
</table>
</section>
<section id="prediction-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="prediction-benchmarks">Prediction Benchmarks</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Key</th>
<th>Benchmark Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>WH_Pred</code></td>
<td>BenchmarkWH_Prediction</td>
</tr>
<tr class="even">
<td><code>Silverbox_Pred</code></td>
<td>BenchmarkSilverbox_Prediction</td>
</tr>
<tr class="odd">
<td><code>Tanks_Pred</code></td>
<td>BenchmarkCascadedTanks_Prediction</td>
</tr>
<tr class="even">
<td><code>CED_Pred</code></td>
<td>BenchmarkCED_Prediction</td>
</tr>
<tr class="odd">
<td><code>EMPS_Pred</code></td>
<td>BenchmarkEMPS_Prediction</td>
</tr>
<tr class="even">
<td><code>NoisyWH_Pred</code></td>
<td>BenchmarkNoisyWH_Prediction</td>
</tr>
<tr class="odd">
<td><code>RobotForward_Pred</code></td>
<td>BenchmarkRobotForward_Prediction</td>
</tr>
<tr class="even">
<td><code>RobotInverse_Pred</code></td>
<td>BenchmarkRobotInverse_Prediction</td>
</tr>
<tr class="odd">
<td><code>Ship_Pred</code></td>
<td>BenchmarkShip_Prediction</td>
</tr>
<tr class="even">
<td><code>QuadPelican_Pred</code></td>
<td>BenchmarkQuadPelican_Prediction</td>
</tr>
<tr class="odd">
<td><code>QuadPi_Pred</code></td>
<td>BenchmarkQuadPi_Prediction</td>
</tr>
</tbody>
</table>
</section>
<section id="workflow-details" class="level2">
<h2 class="anchored" data-anchor-id="workflow-details">Workflow Details</h2>
<p>This section provides more detail on the core concepts and components of the <code>identibench</code> workflow.</p>
<section id="benchmark-types" class="level3">
<h3 class="anchored" data-anchor-id="benchmark-types">Benchmark Types</h3>
<p><code>identibench</code> defines two main types of benchmark tasks, specified using different classes:</p>
<ul>
<li><strong>Simulation (<a href="https://daniel-om-weber.github.io/identibench/benchmark.html#benchmarkspecsimulation"><code>BenchmarkSpecSimulation</code></a>)</strong>:
<ul>
<li><strong>Goal:</strong> Evaluate a model’s ability to perform a free-run simulation, predicting the system’s output over an extended period given the input sequence.</li>
<li><strong>Typical Input to Predictor:</strong> The full input sequence (<code>u_test</code>) and potentially an initial segment of the output sequence (<code>y_test[:init_window]</code>) for warm-up or state initialization.</li>
<li><strong>Expected Output from Predictor:</strong> The predicted output sequence (<code>y_pred</code>) corresponding to the input, usually excluding the warm-up period.</li>
<li><strong>Use Case:</strong> Assessing models intended for long-term prediction, control simulation, or understanding overall system dynamics.</li>
</ul></li>
<li><strong>Prediction (<a href="https://daniel-om-weber.github.io/identibench/benchmark.html#benchmarkspecprediction"><code>BenchmarkSpecPrediction</code></a>)</strong>:
<ul>
<li><strong>Goal:</strong> Evaluate a model’s ability to predict the system’s output <em>k</em> steps into the future based on recent past data.</li>
<li><strong>Typical Input to Predictor:</strong> Often involves windows of past inputs and outputs (e.g., <code>u[t:t+H]</code>, <code>y[t:t+H]</code>).</li>
<li><strong>Expected Output from Predictor:</strong> The predicted output at a specific future time step (e.g., <code>y[t+H+k]</code>). The <code>pred_horizon</code> parameter defines ‘k’, and <code>pred_step</code> defines how frequently predictions are made.</li>
<li><strong>Use Case:</strong> Evaluating models focused on short-to-medium term forecasting, state estimation, or receding horizon control.</li>
</ul></li>
<li><strong><code>init_window</code></strong>: Both benchmark types often use an <code>init_window</code>. This specifies an initial number of time steps whose data might be provided to the model for initialization or warm-up. Importantly, data within this window is typically <em>excluded</em> from the final performance metric calculation to ensure a fair evaluation of the model’s predictive capabilities beyond the initial transient.</li>
</ul>
</section>
<section id="model-interface-build_model" class="level3">
<h3 class="anchored" data-anchor-id="model-interface-build_model">Model Interface (<code>build_model</code>)</h3>
<p>The core of integrating your custom logic is the <code>build_model</code> function you provide to <a href="https://daniel-om-weber.github.io/identibench/benchmark.html#run_benchmark"><code>run_benchmark</code></a>.</p>
<ul>
<li><strong>Purpose:</strong> This function is responsible for defining your model architecture, training it using the provided data, and returning a callable predictor function.</li>
<li><strong>Input (<code>context: TrainingContext</code>):</strong> Your <code>build_model</code> function receives a single argument, <code>context</code>, which is a <a href="https://daniel-om-weber.github.io/identibench/benchmark.html#trainingcontext"><code>TrainingContext</code></a> object. This object gives you access to:
<ul>
<li><code>context.spec</code>: The full specification of the current benchmark being run (including dataset paths, input/output columns, <code>init_window</code>, etc.).</li>
<li><code>context.hyperparameters</code>: A dictionary containing any hyperparameters you passed to <code>run_benchmark</code>. Use this to configure your model or training process.</li>
<li><code>context.seed</code>: A random seed for ensuring reproducibility.</li>
<li>Data Access Methods: Functions like <code>context.get_train_sequences()</code> and <code>context.get_valid_sequences()</code> provide iterators over the raw, full-length training and validation data sequences (as tuples of NumPy arrays <code>(u, y, x)</code>). <strong>Note:</strong> You need to handle any batching or windowing required for your specific training algorithm <em>within</em> your <code>build_model</code> function.</li>
</ul></li>
<li><strong>Output (Predictor <code>Callable</code>):</strong> <code>build_model</code> <em>must</em> return a callable object (e.g., a function, an object’s method) that represents your trained model ready for prediction/simulation. This returned callable will be used internally by <a href="https://daniel-om-weber.github.io/identibench/benchmark.html#run_benchmark"><code>run_benchmark</code></a> on the test set. Its expected signature depends on the benchmark type, but typically it accepts NumPy arrays for test inputs (and potentially initial outputs) and returns a NumPy array containing the predictions.</li>
</ul>
</section>
<section id="running-multiple-benchmarks" class="level3">
<h3 class="anchored" data-anchor-id="running-multiple-benchmarks">Running Multiple Benchmarks</h3>
<p>To evaluate a model across several scenarios efficiently, use the <code>run_multiple_benchmarks</code> function:</p>
<div id="cell-10" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Run on a subset of benchmarks</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>specs_to_run <span class="op">=</span> {</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'WH_Sim'</span>: idb.simulation_benchmarks[<span class="st">'WH_Sim'</span>],</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Silverbox_Sim'</span>: idb.simulation_benchmarks[<span class="st">'Silverbox_Sim'</span>]</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume 'my_build_model' is your defined build function</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>all_results <span class="op">=</span> idb.run_benchmarks(specs_to_run, build_model<span class="op">=</span>build_frols_model,n_times<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>all_results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Starting benchmark run for 2 specifications, repeating each 3 times ---

-- Repetition 1/3 --

[1/6] Running: BenchmarkWH_Simulation (Rep 1)
  -&gt; Success: BenchmarkWH_Simulation (Rep 1) completed.

[2/6] Running: BenchmarkSilverbox_Simulation (Rep 1)
  -&gt; Success: BenchmarkSilverbox_Simulation (Rep 1) completed.

-- Repetition 2/3 --

[3/6] Running: BenchmarkWH_Simulation (Rep 2)
  -&gt; Success: BenchmarkWH_Simulation (Rep 2) completed.

[4/6] Running: BenchmarkSilverbox_Simulation (Rep 2)
  -&gt; Success: BenchmarkSilverbox_Simulation (Rep 2) completed.

-- Repetition 3/3 --

[5/6] Running: BenchmarkWH_Simulation (Rep 3)
  -&gt; Success: BenchmarkWH_Simulation (Rep 3) completed.

[6/6] Running: BenchmarkSilverbox_Simulation (Rep 3)
  -&gt; Success: BenchmarkSilverbox_Simulation (Rep 3) completed.

--- Benchmark run finished. 6/6 individual runs completed successfully. ---</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">benchmark_name</th>
<th data-quarto-table-cell-role="th">dataset_id</th>
<th data-quarto-table-cell-role="th">hyperparameters</th>
<th data-quarto-table-cell-role="th">seed</th>
<th data-quarto-table-cell-role="th">training_time_seconds</th>
<th data-quarto-table-cell-role="th">test_time_seconds</th>
<th data-quarto-table-cell-role="th">benchmark_type</th>
<th data-quarto-table-cell-role="th">metric_name</th>
<th data-quarto-table-cell-role="th">metric_score</th>
<th data-quarto-table-cell-role="th">cs_multisine_rmse</th>
<th data-quarto-table-cell-role="th">cs_arrow_full_rmse</th>
<th data-quarto-table-cell-role="th">cs_arrow_no_extrapolation_rmse</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>BenchmarkWH_Simulation</td>
<td>wh</td>
<td>{}</td>
<td>2406651230</td>
<td>4.944649</td>
<td>1.012850</td>
<td>BenchmarkSpecSimulation</td>
<td>rmse_mV</td>
<td>42.161572</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>BenchmarkSilverbox_Simulation</td>
<td>silverbox</td>
<td>{}</td>
<td>3813113752</td>
<td>2.839149</td>
<td>1.246224</td>
<td>BenchmarkSpecSimulation</td>
<td>rmse_mV</td>
<td>10.732386</td>
<td>8.501941</td>
<td>16.154317</td>
<td>7.5409</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>BenchmarkWH_Simulation</td>
<td>wh</td>
<td>{}</td>
<td>1950649438</td>
<td>4.801520</td>
<td>1.034119</td>
<td>BenchmarkSpecSimulation</td>
<td>rmse_mV</td>
<td>42.161572</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>BenchmarkSilverbox_Simulation</td>
<td>silverbox</td>
<td>{}</td>
<td>1560698088</td>
<td>2.880391</td>
<td>1.217932</td>
<td>BenchmarkSpecSimulation</td>
<td>rmse_mV</td>
<td>10.732386</td>
<td>8.501941</td>
<td>16.154317</td>
<td>7.5409</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>BenchmarkWH_Simulation</td>
<td>wh</td>
<td>{}</td>
<td>3258007268</td>
<td>4.916941</td>
<td>1.021927</td>
<td>BenchmarkSpecSimulation</td>
<td>rmse_mV</td>
<td>42.161572</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>BenchmarkSilverbox_Simulation</td>
<td>silverbox</td>
<td>{}</td>
<td>4194043971</td>
<td>2.937101</td>
<td>1.231710</td>
<td>BenchmarkSpecSimulation</td>
<td>rmse_mV</td>
<td>10.732386</td>
<td>8.501941</td>
<td>16.154317</td>
<td>7.5409</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This function iterates through the provided list or dictionary of benchmark specifications, calling <a href="https://daniel-om-weber.github.io/identibench/benchmark.html#run_benchmark"><code>run_benchmark</code></a> for each one using the same <code>build_model</code> function and hyperparameters.</p>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#calculate mean and std of the results</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>idb.aggregate_benchmark_results(all_results,agg_funcs<span class="op">=</span>[<span class="st">'mean'</span>,<span class="st">'std'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">training_time_seconds</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">test_time_seconds</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">metric_score</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">cs_multisine_rmse</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">cs_arrow_full_rmse</th>
<th colspan="2" data-quarto-table-cell-role="th" data-halign="left">cs_arrow_no_extrapolation_rmse</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
<th data-quarto-table-cell-role="th">mean</th>
<th data-quarto-table-cell-role="th">std</th>
</tr>
<tr class="header">
<th data-quarto-table-cell-role="th">benchmark_name</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">BenchmarkSilverbox_Simulation</td>
<td>2.885547</td>
<td>0.049179</td>
<td>1.231955</td>
<td>0.014147</td>
<td>10.732386</td>
<td>0.0</td>
<td>8.501941</td>
<td>0.0</td>
<td>16.154317</td>
<td>0.0</td>
<td>7.5409</td>
<td>0.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">BenchmarkWH_Simulation</td>
<td>4.887703</td>
<td>0.075912</td>
<td>1.022966</td>
<td>0.010673</td>
<td>42.161572</td>
<td>0.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="data-handling-format" class="level3">
<h3 class="anchored" data-anchor-id="data-handling-format">Data Handling &amp; Format</h3>
<p>Understanding how <code>identibench</code> organizes and stores data is helpful for direct interaction or adding new datasets.</p>
<ul>
<li><strong>Directory Structure:</strong> Datasets are stored under a root directory (default: <code>~/.identibench_data</code>, configurable via the <code>IDENTIBENCH_DATA_ROOT</code> environment variable). The structure follows: <code>DATA_ROOT / [dataset_id] / [subset] / [experiment_file.hdf5]</code>.</li>
<li><strong>Subsets:</strong> Standard subset names are <code>train</code>, <code>valid</code>, and <code>test</code>. An optional <code>train_valid</code> directory might contain combined data.</li>
<li><strong>Download &amp; Cache:</strong> Data is downloaded automatically when a benchmark requires it and cached locally to avoid re-downloads. The <code>identibench.datasets.download_all_datasets</code> function can fetch all datasets at once.</li>
<li><strong>File Format:</strong> Processed time-series data is stored in the <strong>HDF5 (<code>.hdf5</code>)</strong> format.</li>
<li><strong>HDF5 Structure:</strong>
<ul>
<li>Each <code>.hdf5</code> file typically represents one experimental run.</li>
<li>Signals (inputs, outputs, states) are stored as separate 1-dimensional datasets within the file, named conventionally as <code>u0</code>, <code>u1</code>, …, <code>y0</code>, <code>y1</code>, …, <code>x0</code>, …</li>
<li>Data is usually stored as <code>float32</code> NumPy arrays.</li>
<li>Metadata like sampling frequency (<code>fs</code>) and suggested initialization window size (<code>init_sz</code>) are stored as attributes on the root group of the HDF5 file.</li>
<li><em>Example Structure:</em> <code>my_dataset/       └── train/           └── train_run_1.hdf5               ├── u0 (Dataset: shape=(N,), dtype=float32)               ├── y0 (Dataset: shape=(N,), dtype=float32)               └── Attributes:                   └── fs (Attribute: float)</code></li>
</ul></li>
<li><strong>Extensibility:</strong> Adhering to this HDF5 format ensures compatibility when adding new dataset loaders. Helper functions like <a href="https://daniel-om-weber.github.io/identibench/utils.html#write_array"><code>identibench.utils.write_array</code></a> facilitate creating files in the correct format.</li>
</ul>
</section>
<section id="understanding-benchmark-results" class="level3">
<h3 class="anchored" data-anchor-id="understanding-benchmark-results">Understanding Benchmark Results</h3>
<p>The <a href="https://daniel-om-weber.github.io/identibench/benchmark.html#run_benchmark"><code>run_benchmark</code></a> function returns a dictionary containing detailed results of the experiment. Key entries include:</p>
<ul>
<li><code>benchmark_name</code> (<code>str</code>): The unique name of the benchmark specification used.</li>
<li><code>dataset_id</code> (<code>str</code>): Identifier for the dataset source.</li>
<li><code>hyperparameters</code> (<code>dict</code>): The hyperparameters dictionary passed to the run.</li>
<li><code>seed</code> (<code>int</code>): The random seed used for the run.</li>
<li><code>training_time_seconds</code> (<code>float</code>): Wall-clock time spent inside your <code>build_model</code> function.</li>
<li><code>test_time_seconds</code> (<code>float</code>): Wall-clock time spent evaluating the returned predictor on the test set.</li>
<li><code>benchmark_type</code> (<code>str</code>): The type of benchmark run (e.g., <code>'BenchmarkSpecSimulation'</code>).</li>
<li><code>metric_name</code> (<code>str</code>): The name of the primary metric function defined in the spec.</li>
<li><code>metric_score</code> (<code>float</code>): The calculated score for the primary metric on the test set (aggregated if multiple test files).</li>
<li><code>custom_scores</code> (<code>dict</code>): Any additional scores calculated by custom evaluation logic specific to the benchmark.</li>
<li><code>model_predictions</code> (<code>list</code>): A list containing the raw outputs. For simulation, it’s typically <code>[(y_pred_test1, y_true_test1), (y_pred_test2, y_true_test2), ...]</code>. For prediction, the structure might be nested reflecting windowed predictions.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/daniel-om-weber\.github\.io\/identibench");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/daniel-om-weber/identibench/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>