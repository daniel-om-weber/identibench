{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Benchmark Workshop Datasets\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sysbench_loader.core import *\n",
    "import nonlinear_benchmarks\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = Path('./tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiener Hammerstein Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def wiener_hammerstein(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    save_path = save_path / 'wh'\n",
    "    train_val, test = nonlinear_benchmarks.WienerHammerBenchMark()\n",
    "    split_idx = 80_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'wh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset not found downloading from http://www.ee.kth.se/~hjalmars/ifac_tc11_benchmarks/2009_wienerhammerstein/WienerHammerBenchMark.mat \n",
      " in C:\\Users\\danie\\AppData\\Local\\nonlinear_benchmarks/WienerHammerBenchMark\\WienerHammerBenchMark.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "wiener_hammerstein(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silverbox Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def silverbox(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    save_path = save_path / 'silverbox'\n",
    "    train_val, test = nonlinear_benchmarks.Silverbox()\n",
    "    split_idx = 78_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'silverbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset not found downloading from https://drive.google.com/file/d/17iS-6oBUUgrmiAcrZoG9S5sOaljZnDSy/view \n",
      " in C:\\Users\\danie\\AppData\\Local\\nonlinear_benchmarks/Silverbox\\SilverboxFiles.zip\n",
      "extracting file...\n",
      "save_loc='C:\\\\Users\\\\danie\\\\AppData\\\\Local\\\\nonlinear_benchmarks/Silverbox\\\\SilverboxFiles.zip'\n"
     ]
    }
   ],
   "source": [
    "silverbox(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascaded Tanks Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cascaded_tanks(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    'the cascaded_tanks dataset, '\n",
    "    save_path = save_path / 'cascaded_tanks'\n",
    "    train_val, test = nonlinear_benchmarks.Cascaded_Tanks()\n",
    "    train = train_val\n",
    "    valid = train_val\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'cascaded_tanks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset not found downloading from https://drive.google.com/file/d/1HnQf_gu0g_UlggoBqy2s34l9YJiFdN01/view \n",
      " in C:\\Users\\danie\\AppData\\Local\\nonlinear_benchmarks/Cascaded_Tanks\\CascadedTanksFiles.zip\n",
      "extracting file...\n",
      "save_loc='C:\\\\Users\\\\danie\\\\AppData\\\\Local\\\\nonlinear_benchmarks/Cascaded_Tanks\\\\CascadedTanksFiles.zip'\n"
     ]
    }
   ],
   "source": [
    "cascaded_tanks(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def emps(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    'the emps dataset, '\n",
    "    save_path = save_path / 'emps'\n",
    "    train_val, test = nonlinear_benchmarks.EMPS()\n",
    "    split_idx = 18_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'emps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset not found downloading from https://drive.google.com/file/d/1zwoXYa9-3f8NQ0ohzmjpF7UxbNgRTHkS/view \n",
      " in C:\\Users\\danie\\AppData\\Local\\nonlinear_benchmarks/EMPS\\EMPS.zip\n",
      "extracting file...\n",
      "save_loc='C:\\\\Users\\\\danie\\\\AppData\\\\Local\\\\nonlinear_benchmarks/EMPS\\\\EMPS.zip'\n"
     ]
    }
   ],
   "source": [
    "emps(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#clean temporary hdf5 file\n",
    "shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
