{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Benchmark Workshop Datasets\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sysbench_loader.core import *\n",
    "import nonlinear_benchmarks\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = Path('./tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiener Hammerstein Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def wiener_hammerstein(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    save_path = save_path / 'wh'\n",
    "    train_val, test = nonlinear_benchmarks.WienerHammerBenchMark()\n",
    "    split_idx = 80_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'wh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiener_hammerstein(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silverbox Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def silverbox(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    save_path = save_path / 'silverbox'\n",
    "    train_val, test = nonlinear_benchmarks.Silverbox()\n",
    "    split_idx = 78_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'silverbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silverbox(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascaded Tanks Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cascaded_tanks(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    'the cascaded_tanks dataset, '\n",
    "    save_path = save_path / 'cascaded_tanks'\n",
    "    train_val, test = nonlinear_benchmarks.Cascaded_Tanks()\n",
    "    train = train_val\n",
    "    valid = train_val\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'cascaded_tanks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascaded_tanks(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def emps(\n",
    "        save_path: Path #directory the files are written to, created if it does not exist\n",
    "):\n",
    "    'the emps dataset, '\n",
    "    save_path = save_path / 'emps'\n",
    "    train_val, test = nonlinear_benchmarks.EMPS()\n",
    "    split_idx = 18_000\n",
    "    train = train_val[:split_idx]\n",
    "    valid = train_val[split_idx:]\n",
    "\n",
    "    dataset_to_hdf5(train,valid,test,save_path / 'emps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emps(tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Wiener Hammerstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset not found downloading from https://data.4tu.nl/file/1f194001-affa-4459-870a-ad9e9d9146f9/2dbbc046-1ac2-43b2-bf4e-53b5a4be8b96 \n",
      " in C:\\Users\\danie\\AppData\\Local\\nonlinear_benchmarks/WienHammer\\WienerHammersteinFiles.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% |#########################################                               |\r"
     ]
    }
   ],
   "source": [
    "# nonlinear_benchmarks.not_splitted_benchmarks.WienerHammerstein_Process_Noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#clean temporary hdf5 file\n",
    "# shutil.rmtree(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
